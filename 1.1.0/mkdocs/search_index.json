{
    "docs": [
        {
            "location": "/", 
            "text": "OAP Project Overview\n\n\nOptimized Analytics Package (OAP) for Spark platform is a open source project for multiple Spark optimizations and features driving by Intel and the community.\nSpark is powerful and well optimized in a lot of aspects.  But we still face a few challenges for Spark to the next level performance.\n\n\n\n\n\n\nThe JVM and row-based computing engine preventing Spark to be fully optimized for Intel hardware, for example AVX/AVX512, GPU\n\n\n\n\n\n\nThe current implementation of key aspects, such as memory management \n shuffle didn\u2019t consider the latest technology advancements,  like PMEM\n\n\n\n\n\n\nThe batch processing engine a lot of times cannot satisfy the need of queries with high performance requirement.\n\n\n\n\n\n\nOAP Project is targeted to optimize Spark in these aspects above, now it has 8 components including SQL DS Cache,\nNative SQL Engine, Arrow Data Source, OAP MLlib, PMem Spill, PMem Common, PMem Shuffle and Remote Shuffle.\n\n\n\n\nGuide\n\n\nPlease refer to the total OAP project installation and development guide below.\n\n\n\n\nOAP Installation Guide\n\n\nOAP Developer Guide\n\n\n\n\nYou can get more detailed information from each module web page of OAP Project below, or from the left sidebar navigation.\n\n\n\n\nSQL DS Cache\n\n\nNative SQL Engine\n\n\nArrow Data Source\n\n\nOAP MLlib\n\n\nPMem Shuffle\n\n\nRemote Shuffle\n\n\nPMem Spill\n\n\nPMem Common", 
            "title": "Home"
        }, 
        {
            "location": "/#oap-project-overview", 
            "text": "Optimized Analytics Package (OAP) for Spark platform is a open source project for multiple Spark optimizations and features driving by Intel and the community.\nSpark is powerful and well optimized in a lot of aspects.  But we still face a few challenges for Spark to the next level performance.    The JVM and row-based computing engine preventing Spark to be fully optimized for Intel hardware, for example AVX/AVX512, GPU    The current implementation of key aspects, such as memory management   shuffle didn\u2019t consider the latest technology advancements,  like PMEM    The batch processing engine a lot of times cannot satisfy the need of queries with high performance requirement.    OAP Project is targeted to optimize Spark in these aspects above, now it has 8 components including SQL DS Cache,\nNative SQL Engine, Arrow Data Source, OAP MLlib, PMem Spill, PMem Common, PMem Shuffle and Remote Shuffle.", 
            "title": "OAP Project Overview"
        }, 
        {
            "location": "/#guide", 
            "text": "Please refer to the total OAP project installation and development guide below.   OAP Installation Guide  OAP Developer Guide   You can get more detailed information from each module web page of OAP Project below, or from the left sidebar navigation.   SQL DS Cache  Native SQL Engine  Arrow Data Source  OAP MLlib  PMem Shuffle  Remote Shuffle  PMem Spill  PMem Common", 
            "title": "Guide"
        }, 
        {
            "location": "/OAP-Developer-Guide/", 
            "text": "This document contains the instructions \n scripts on installing necessary dependencies and building OAP modules. \nYou can get more detailed information from OAP each module below.\n\n\n\n\nSQL Index and Data Source Cache\n\n\nPMem Common\n\n\nPMem Spill\n\n\nPMem Shuffle\n\n\nRemote Shuffle\n\n\nOAP MLlib\n\n\nNative SQL Engine\n\n\n\n\nBuilding OAP\n\n\nPrerequisites\n\n\nWe provide scripts to help automatically install dependencies required, please change to \nroot\n user and run:\n\n\n# git clone -b branch-1.1-spark-3.x https://github.com/oap-project/oap-tools.git\n# cd oap-tools\n# sh dev/install-compile-time-dependencies.sh\n\n\n\n\nNote\n: \nbranch-1.1-spark-3.x\n is for OAP modules version \nv1.1.0-spark-3.0.0\n\n\nThen the dependencies below will be installed:\n\n\n\n\nCmake\n\n\nGCC \n 7\n\n\nMemkind\n\n\nVmemcache\n\n\nHPNL\n\n\nPMDK\n  \n\n\nOneAPI\n\n\nArrow\n\n\nLLVM\n \n\n\n\n\nRun the following command to learn more.\n\n\n# sh dev/scripts/prepare_oap_env.sh --help\n\n\n\n\nRun the following command to automatically install specific dependency such as Maven.\n\n\n# sh dev/scripts/prepare_oap_env.sh --prepare_maven\n\n\n\n\n\n\nRequirements for Shuffle Remote PMem Extension\n\nIf enable Shuffle Remote PMem extension with RDMA, you can refer to \nPMem Shuffle\n to configure and validate RDMA in advance.\n\n\n\n\nBuilding\n\n\nOAP is built with \nApache Maven\n and Oracle Java 8.\n\n\nTo build OAP package, run command below then you can find a tarball named \noap-$VERSION-bin-spark-$VERSION.tar.gz\n under directory \n$OAP_TOOLS_HOME/dev/release-package\n.\n\n\n$ sh $OAP_TOOLS_HOME/dev/compile-oap.sh\n\n\n\n\nBuilding specified OAP Module, such as \nsql-ds-cache\n, run:\n\n\n$ sh $OAP_TOOLS_HOME/dev/compile-oap.sh --sql-ds-cache", 
            "title": "OAP Developer Guide"
        }, 
        {
            "location": "/OAP-Developer-Guide/#building-oap", 
            "text": "", 
            "title": "Building OAP"
        }, 
        {
            "location": "/OAP-Developer-Guide/#prerequisites", 
            "text": "We provide scripts to help automatically install dependencies required, please change to  root  user and run:  # git clone -b branch-1.1-spark-3.x https://github.com/oap-project/oap-tools.git\n# cd oap-tools\n# sh dev/install-compile-time-dependencies.sh  Note :  branch-1.1-spark-3.x  is for OAP modules version  v1.1.0-spark-3.0.0  Then the dependencies below will be installed:   Cmake  GCC   7  Memkind  Vmemcache  HPNL  PMDK     OneAPI  Arrow  LLVM     Run the following command to learn more.  # sh dev/scripts/prepare_oap_env.sh --help  Run the following command to automatically install specific dependency such as Maven.  # sh dev/scripts/prepare_oap_env.sh --prepare_maven   Requirements for Shuffle Remote PMem Extension \nIf enable Shuffle Remote PMem extension with RDMA, you can refer to  PMem Shuffle  to configure and validate RDMA in advance.", 
            "title": "Prerequisites"
        }, 
        {
            "location": "/OAP-Developer-Guide/#building", 
            "text": "OAP is built with  Apache Maven  and Oracle Java 8.  To build OAP package, run command below then you can find a tarball named  oap-$VERSION-bin-spark-$VERSION.tar.gz  under directory  $OAP_TOOLS_HOME/dev/release-package .  $ sh $OAP_TOOLS_HOME/dev/compile-oap.sh  Building specified OAP Module, such as  sql-ds-cache , run:  $ sh $OAP_TOOLS_HOME/dev/compile-oap.sh --sql-ds-cache", 
            "title": "Building"
        }, 
        {
            "location": "/OAP-Installation-Guide/", 
            "text": "This document introduces how to install OAP and its dependencies on your cluster nodes by \nConda\n. \nFollow steps below on \nevery node\n of your cluster to set right environment for each machine.\n\n\nContents\n\n\n\n\nPrerequisites\n\n\nInstalling OAP\n\n\nConfiguration\n\n\n\n\nPrerequisites\n\n\n\n\n\n\nOS Requirements\n\nWe have tested OAP on Fedora 29 and CentOS 7.6 (kernel-4.18.16). We recommend you use \nFedora 29 CentOS 7.6 or above\n. Besides, for \nMemkind\n we recommend you use \nkernel above 3.10\n.\n\n\n\n\n\n\nConda Requirements\n \n\nInstall Conda on your cluster nodes with below commands and follow the prompts on the installer screens.:\n\n\n\n\n\n\n$ wget -c https://repo.continuum.io/miniconda/Miniconda2-latest-Linux-x86_64.sh\n$ chmod +x Miniconda2-latest-Linux-x86_64.sh \n$ bash Miniconda2-latest-Linux-x86_64.sh \n\n\n\n\nFor changes to take effect, \nclose and re-open\n your current shell. \nTo test your installation,  run the command \nconda list\n in your terminal window. A list of installed packages appears if it has been installed correctly.\n\n\nInstalling OAP\n\n\nCreate a Conda environment and install OAP Conda package.\n\n\n$ conda create -n oapenv -y python=3.7\n$ conda activate oapenv\n$ conda install -c conda-forge -c intel -y oap=1.1.0\n\n\n\n\nOnce finished steps above, you have completed OAP dependencies installation and OAP building, and will find built OAP jars under \n$HOME/miniconda2/envs/oapenv/oap_jars\n\n\nDependencies below are required by OAP and all of them are included in OAP Conda package, they will be automatically installed in your cluster when you Conda install OAP. Ensure you have activated environment which you created in the previous steps.\n\n\n\n\nArrow\n\n\nPlasma\n\n\nMemkind\n\n\nVmemcache\n\n\nHPNL\n\n\nPMDK\n  \n\n\nOneAPI\n\n\n\n\nExtra Steps for Shuffle Remote PMem Extension\n\n\nIf you use one of OAP features -- \nPMmem Shuffle\n with \nRDMA\n, you need to configure and validate RDMA, please refer to \nPMem Shuffle\n for the details.\n\n\nConfiguration\n\n\nOnce finished steps above, make sure libraries installed by Conda can be linked by Spark, please add the following configuration settings to \n$SPARK_HOME/conf/spark-defaults.conf\n.\n\n\nspark.executorEnv.LD_LIBRARY_PATH   $HOME/miniconda2/envs/oapenv/lib\nspark.executor.extraLibraryPath     $HOME/miniconda2/envs/oapenv/lib\nspark.driver.extraLibraryPath       $HOME/miniconda2/envs/oapenv/lib\nspark.executor.extraClassPath       $HOME/miniconda2/envs/oapenv/oap_jars/$OAP_FEATURE.jar\nspark.driver.extraClassPath         $HOME/miniconda2/envs/oapenv/oap_jars/$OAP_FEATURE.jar\n\n\n\n\nThen you can follow the corresponding feature documents for more details to use them.", 
            "title": "OAP Installation Guide"
        }, 
        {
            "location": "/OAP-Installation-Guide/#contents", 
            "text": "Prerequisites  Installing OAP  Configuration", 
            "title": "Contents"
        }, 
        {
            "location": "/OAP-Installation-Guide/#prerequisites", 
            "text": "OS Requirements \nWe have tested OAP on Fedora 29 and CentOS 7.6 (kernel-4.18.16). We recommend you use  Fedora 29 CentOS 7.6 or above . Besides, for  Memkind  we recommend you use  kernel above 3.10 .    Conda Requirements   \nInstall Conda on your cluster nodes with below commands and follow the prompts on the installer screens.:    $ wget -c https://repo.continuum.io/miniconda/Miniconda2-latest-Linux-x86_64.sh\n$ chmod +x Miniconda2-latest-Linux-x86_64.sh \n$ bash Miniconda2-latest-Linux-x86_64.sh   For changes to take effect,  close and re-open  your current shell. \nTo test your installation,  run the command  conda list  in your terminal window. A list of installed packages appears if it has been installed correctly.", 
            "title": "Prerequisites"
        }, 
        {
            "location": "/OAP-Installation-Guide/#installing-oap", 
            "text": "Create a Conda environment and install OAP Conda package.  $ conda create -n oapenv -y python=3.7\n$ conda activate oapenv\n$ conda install -c conda-forge -c intel -y oap=1.1.0  Once finished steps above, you have completed OAP dependencies installation and OAP building, and will find built OAP jars under  $HOME/miniconda2/envs/oapenv/oap_jars  Dependencies below are required by OAP and all of them are included in OAP Conda package, they will be automatically installed in your cluster when you Conda install OAP. Ensure you have activated environment which you created in the previous steps.   Arrow  Plasma  Memkind  Vmemcache  HPNL  PMDK     OneAPI", 
            "title": "Installing OAP"
        }, 
        {
            "location": "/OAP-Installation-Guide/#extra-steps-for-shuffle-remote-pmem-extension", 
            "text": "If you use one of OAP features --  PMmem Shuffle  with  RDMA , you need to configure and validate RDMA, please refer to  PMem Shuffle  for the details.", 
            "title": "Extra Steps for Shuffle Remote PMem Extension"
        }, 
        {
            "location": "/OAP-Installation-Guide/#configuration", 
            "text": "Once finished steps above, make sure libraries installed by Conda can be linked by Spark, please add the following configuration settings to  $SPARK_HOME/conf/spark-defaults.conf .  spark.executorEnv.LD_LIBRARY_PATH   $HOME/miniconda2/envs/oapenv/lib\nspark.executor.extraLibraryPath     $HOME/miniconda2/envs/oapenv/lib\nspark.driver.extraLibraryPath       $HOME/miniconda2/envs/oapenv/lib\nspark.executor.extraClassPath       $HOME/miniconda2/envs/oapenv/oap_jars/$OAP_FEATURE.jar\nspark.driver.extraClassPath         $HOME/miniconda2/envs/oapenv/oap_jars/$OAP_FEATURE.jar  Then you can follow the corresponding feature documents for more details to use them.", 
            "title": "Configuration"
        }, 
        {
            "location": "/README/", 
            "text": "How to build documentation\n\n\nBefore we build documentation on Github Pages web with scripts, some requeirements need to be satisfied.\n\n\nBuilding oap-project.github.io\n\n\nBefore build documentation, please use conda to install mkdocs 0.16.3 with commands below.\n\n\n$ wget -c https://repo.continuum.io/miniconda/Miniconda2-latest-Linux-x86_64.sh\n$ chmod +x Miniconda2-latest-Linux-x86_64.sh\n$ bash Miniconda2-latest-Linux-x86_64.sh\n\n\n\n\nFor changes to take effect, close and re-open your current shell.\n\n\nThen install mkdocs 0.16.3 \n\n\nconda install -c conda-forge mkdocs\n\n\n\n\nUse script to generate OAP Project Pages website. \n./gen_oap_site.sh\n with version (branch or tag) to build docs\n\n\n$  git clone https://github.com/oap-project/oap-tools.git\n$  ./oap-tools/dev/gen_oap_site.sh  v1.1.0\n\n\n\n\nBuilding feature repo web\n\n\nBefore build documentation of oap-project feature repositories, please make sure your Python version \n= 3.6.\n\n\nRun commands below to generate OAP Project feature website. \n./gen_component_site.sh\n with version (branch or tag) \n\n\n$  git clone https://github.com/oap-project/oap-tools.git\n$  ./oap-tools/dev/gen_component_site.sh   v1.1.0", 
            "title": "README"
        }, 
        {
            "location": "/README/#how-to-build-documentation", 
            "text": "Before we build documentation on Github Pages web with scripts, some requeirements need to be satisfied.", 
            "title": "How to build documentation"
        }, 
        {
            "location": "/README/#building-oap-projectgithubio", 
            "text": "Before build documentation, please use conda to install mkdocs 0.16.3 with commands below.  $ wget -c https://repo.continuum.io/miniconda/Miniconda2-latest-Linux-x86_64.sh\n$ chmod +x Miniconda2-latest-Linux-x86_64.sh\n$ bash Miniconda2-latest-Linux-x86_64.sh  For changes to take effect, close and re-open your current shell.  Then install mkdocs 0.16.3   conda install -c conda-forge mkdocs  Use script to generate OAP Project Pages website.  ./gen_oap_site.sh  with version (branch or tag) to build docs  $  git clone https://github.com/oap-project/oap-tools.git\n$  ./oap-tools/dev/gen_oap_site.sh  v1.1.0", 
            "title": "Building oap-project.github.io"
        }, 
        {
            "location": "/README/#building-feature-repo-web", 
            "text": "Before build documentation of oap-project feature repositories, please make sure your Python version  = 3.6.  Run commands below to generate OAP Project feature website.  ./gen_component_site.sh  with version (branch or tag)   $  git clone https://github.com/oap-project/oap-tools.git\n$  ./oap-tools/dev/gen_component_site.sh   v1.1.0", 
            "title": "Building feature repo web"
        }
    ]
}